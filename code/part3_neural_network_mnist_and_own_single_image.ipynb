{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# this version trains using the MNIST dataset, then tests on our own images\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper to load data from PNG image files\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with our own image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ... my_own_images/2828_my_own_image.png\n",
      "min =  0.01\n",
      "max =  1.0\n",
      "[[ 0.0027999 ]\n",
      " [ 0.0037432 ]\n",
      " [ 0.01817265]\n",
      " [ 0.92297039]\n",
      " [ 0.00246505]\n",
      " [ 0.00704918]\n",
      " [ 0.17021171]\n",
      " [ 0.02702109]\n",
      " [ 0.00896418]\n",
      " [ 0.01368427]]\n",
      "network says  3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD1VJREFUeJzt3V+MVGWax/Hfs8gEUYiy9iBRkMGIUUyEpGKM/zLrMOIo\nCYJ/AhcGEp0eDTPuJF6sgYvVRAkSYeLFxohKBjYsg4YxoqgbJas4ZjEWxhUcdFVsAgjShonDXEg3\n8OxFH2db7PNWWXW6TnU/30/S6arznLfrseKPU1VvnfOauwtAPP9QdgMAykH4gaAIPxAU4QeCIvxA\nUIQfCIrwA0ERfiAowg8EdVorH+ycc87xyZMnt/IhgVC6urr01VdfWT37NhV+M7tR0uOSRkh62t2X\np/afPHmyqtVqMw8JIKFSqdS9b8Mv+81shKR/k/QLSZdKWmBmlzb69wC0VjPv+a+Q9Km773H3Hkl/\nkDSnmLYADLZmwn+epH397u/Ptn2HmXWaWdXMqt3d3U08HIAiDfqn/e6+2t0r7l7p6OgY7IcDUKdm\nwn9A0sR+98/PtgEYApoJ/7uSLjKzn5jZjyTNl7S5mLYADLaGp/rc/biZ/VrSf6pvqm+Nu39YWGcA\nBlVT8/zu/rKklwvqBUAL8fVeICjCDwRF+IGgCD8QFOEHgiL8QFAtPZ8fAzt06FCy/tRTTyXru3bt\nyq0dPHgwOfbYsWPJuln61PBa9dSKUBdffHFy7A033JCsz507N1kfPXp0sh4dR34gKMIPBEX4gaAI\nPxAU4QeCIvxAUEz1tcA777yTrF933XXJek9PT5HttI1az8u6deuS9TFjxiTrr776am7tqquuSo6N\ngCM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFPH8Bap2Se+211ybrx48fT9ZXrFiRrM+fPz+3Nnbs\n2OTYESNGJOu1TtmtJXVK7969e5Nja83zr1y5MlmfOXNmbm3//v3JsePGjUvWhwOO/EBQhB8IivAD\nQRF+ICjCDwRF+IGgCD8QVFPz/GbWJemopBOSjrt7pYim2tHJkydza/fee29ybG9vb7Je69Lcd999\nd7I+VE2bNi1Zf/TRR5P1Cy64IFlfvHhxbu3+++9Pjl2zZk2y3uz3H9pBEV/y+Sd3/6qAvwOghXjZ\nDwTVbPhd0utmtsPMOotoCEBrNPuy/xp3P2BmP5b0mpl95O7b+u+Q/aPQKUmTJk1q8uEAFKWpI7+7\nH8h+H5b0vKQrBthntbtX3L3S0dHRzMMBKFDD4TezM8xszLe3Jd0gKX/FSABtpZmX/eMlPZ9NeZwm\n6T/cPf9ayQDaiqXOty5apVLxarXasscr0tKlS3Nry5YtS4698sork/W33norWT/tNC67MJBa35+4\n8MILc2v79u1Ljv3444+T9alTpybrZalUKqpWq3V9CYGpPiAowg8ERfiBoAg/EBThB4Ii/EBQzCHV\n6Y033sitjR8/Pjl2y5YtyTpTeY0ZOXJksr5q1arc2u23354cW+uy4Q8//HCyPhRw5AeCIvxAUIQf\nCIrwA0ERfiAowg8ERfiBoJhgrtPWrVtza6nLekvS6NGji24HdWjmsnHd3d0FdtKeOPIDQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFDM89dp1KhRZbeAU3zzzTfJejNLm8+aNavhsUMFR34gKMIPBEX4gaAI\nPxAU4QeCIvxAUIQfCKrmPL+ZrZE0W9Jhd78s2zZO0kZJkyV1SbrD3f8yeG0iop6enmR93rx5yfrO\nnTtza4sWLUqOnTt3brI+HNRz5P+9pBtP2faApK3ufpGkrdl9AENIzfC7+zZJR07ZPEfS2uz2Wkm3\nFNwXgEHW6Hv+8e5+MLt9SFJ6vSoAbafpD/zc3SV5Xt3MOs2sambVCNdFA4aKRsP/pZlNkKTs9+G8\nHd19tbtX3L3S0dHR4MMBKFqj4d8saWF2e6GkF4ppB0Cr1Ay/mW2Q9N+SLjaz/WZ2l6Tlkn5uZp9I\nmpndBzCE1Jznd/cFOaWfFdwLhqBaaxYcO3Yst7Zr167k2Pvuuy9Z3759e7I+c+bM3NoTTzyRHGtm\nyfpwwDf8gKAIPxAU4QeCIvxAUIQfCIrwA0Fx6e5hoLe3N7e2adOm5NgNGzYk659//nmy/sUXXyTr\nR46cek7Y/+v7Znjjbr311mR93bp1uTUuxc6RHwiL8ANBEX4gKMIPBEX4gaAIPxAU4QeCYp5/GHjk\nkUdyaw899FALOynWWWedlaxff/31yXpqCe/Ro0c31NNwwpEfCIrwA0ERfiAowg8ERfiBoAg/EBTh\nB4Jinn8YmDNnTm5t9+7dybHNXqK6mXPyt23blqwfOnQoWV+8eHGyvnTp0tzajh07kmOnTJmSrA8H\nHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKia8/xmtkbSbEmH3f2ybNuDkn4pqTvbbYm7vzxYTSJt\nxowZubWNGze2sJMf5sSJE8n6Z599lqw/88wzyfqKFStya5VKJTl2z549yXqtaw0MBfUc+X8v6cYB\ntv/O3adnPwQfGGJqht/dt0nKX3YFwJDUzHv+35jZB2a2xszOLqwjAC3RaPifkDRF0nRJByWtzNvR\nzDrNrGpm1e7u7rzdALRYQ+F39y/d/YS7n5T0lKQrEvuudveKu1c6Ojoa7RNAwRoKv5lN6Hd3rqRd\nxbQDoFXqmerbIOmnks4xs/2S/lXST81suiSX1CXpV4PYI4BBUDP87r5ggM3pCVagDiNGjEjWp06d\nmqwvX748WT9+/HhubdWqVcmxL774YrJ+5513JutDAd/wA4Ii/EBQhB8IivADQRF+ICjCDwTFpbsx\nZNW67Pjs2bNza7Wm+rq6uhppaUjhyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHPj2Gr1inDKSdP\nniywk/bEkR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKeH8PW22+/3fDYiRMnFthJe+LIDwRF+IGg\nCD8QFOEHgiL8QFCEHwiK8ANB1ZznN7OJktZJGi/JJa1298fNbJykjZImS+qSdIe7/2XwWgW+q6en\nJ1l/7LHHcmu1zvW/7bbbGuppKKnnyH9c0v3ufqmkKyUtNrNLJT0gaau7XyRpa3YfwBBRM/zuftDd\n38tuH5W0W9J5kuZIWpvttlbSLYPVJIDi/aD3/GY2WdIMSe9IGu/uB7PSIfW9LQAwRNQdfjM7U9Im\nSb9197/2r7m7q+/zgIHGdZpZ1cyq3d3dTTULoDh1hd/MRqov+Ovd/Y/Z5i/NbEJWnyDp8EBj3X21\nu1fcvdLR0VFEzwAKUDP81rcU6jOSdrt7/6VNN0tamN1eKOmF4tsDMFjqOaX3akl3StppZu9n25ZI\nWi7pWTO7S9JeSXcMTout0dvbm6xv3rw5tzZr1qzk2DPPPLOhnqLrezeZb8mSJcn6kSNHcmv33HNP\ncuzYsWOT9eGgZvjd/U+S8hZC/1mx7QBoFb7hBwRF+IGgCD8QFOEHgiL8QFCEHwiKS3dnqtVqsp46\nxXP27NnJsc8991yyPmrUqGQ9qmeffTZZX7lyZbJ+7rnn5tZWrFjRUE/DCUd+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiKef7MjBkzkvVLLrkkt/bSSy8lx86bNy9Zf/LJJ5P1888/P1nvu95Ke0pdJ2H9\n+vXJsZ2dncl6rf/uN998M7c2ZsyY5NgIOPIDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDM82dqnVO/\nY8eO3Fqt6/a/8soryfqkSZOS9dNPPz1Zv/nmm3NrV199dXJsraWqa/n666+T9aeffjq3tnfv3uTY\nkSNHJutbtmxJ1qdOnZqsR8eRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCslproJvZREnrJI2X5JJW\nu/vjZvagpF9K6s52XeLuL6f+VqVS8VrXxx+Kenp6kvW1a9cm67Wu6799+/Zk/ejRo8l6mVLn3C9a\ntCg5dtmyZcl66rr8UVUqFVWr1bou8FDPl3yOS7rf3d8zszGSdpjZa1ntd+7+WKONAihPzfC7+0FJ\nB7PbR81st6TzBrsxAIPrB73nN7PJkmZIeifb9Bsz+8DM1pjZ2TljOs2sambV7u7ugXYBUIK6w29m\nZ0raJOm37v5XSU9ImiJpuvpeGQy4cJq7r3b3irtXOjo6CmgZQBHqCr+ZjVRf8Ne7+x8lyd2/dPcT\n7n5S0lOSrhi8NgEUrWb4re/j2mck7Xb3Vf22T+i321xJu4pvD8BgqWeq7xpJb0naKelktnmJpAXq\ne8nvkrok/Sr7cDDXcJ3qG2wnTpxI1j/66KPc2r59+5Jjm73sd61Tgi+//PLcGm8Di1foVJ+7/0nS\nQH8sOacPoL3xDT8gKMIPBEX4gaAIPxAU4QeCIvxAUFy6ewioNZc+bdq0hmqIjSM/EBThB4Ii/EBQ\nhB8IivADQRF+ICjCDwRV83z+Qh/MrFtS/3WZz5H0Vcsa+GHatbd27Uuit0YV2dsF7l7XhRJaGv7v\nPbhZ1d0rpTWQ0K69tWtfEr01qqzeeNkPBEX4gaDKDv/qkh8/pV17a9e+JHprVCm9lfqeH0B5yj7y\nAyhJKeE3sxvN7GMz+9TMHiijhzxm1mVmO83sfTMr9Trj2TJoh81sV79t48zsNTP7JPs94DJpJfX2\noJkdyJ67983sppJ6m2hm/2VmfzazD83sn7PtpT53ib5Ked5a/rLfzEZI+l9JP5e0X9K7kha4+59b\n2kgOM+uSVHH30ueEzew6SX+TtM7dL8u2rZB0xN2XZ/9wnu3u/9ImvT0o6W9lr9ycLSgzof/K0pJu\nkbRIJT53ib7uUAnPWxlH/iskferue9y9R9IfJM0poY+25+7bJB05ZfMcSWuz22vV9z9Py+X01hbc\n/aC7v5fdPirp25WlS33uEn2Voozwnyep/zIy+9VeS367pNfNbIeZdZbdzADG91sZ6ZCk8WU2M4Ca\nKze30ikrS7fNc9fIitdF4wO/77vG3adL+oWkxdnL27bkfe/Z2mm6pq6Vm1tlgJWl/67M567RFa+L\nVkb4D0ia2O/++dm2tuDuB7LfhyU9r/ZbffjLbxdJzX4fLrmfv2unlZsHWllabfDctdOK12WE/11J\nF5nZT8zsR5LmS9pcQh/fY2ZnZB/EyMzOkHSD2m/14c2SFma3F0p6ocRevqNdVm7OW1laJT93bbfi\ntbu3/EfSTer7xP8zSUvL6CGnrymS/if7+bDs3iRtUN/LwF71fTZyl6R/lLRV0ieSXpc0ro16+3f1\nreb8gfqCNqGk3q5R30v6DyS9n/3cVPZzl+irlOeNb/gBQfGBHxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8ERfiBoP4PYja7cJBT5mIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f674b6e9400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network withour own images\n",
    "\n",
    "# load image data from png files into an array\n",
    "print (\"loading ... my_own_images/2828_my_own_image.png\")\n",
    "img_array = scipy.misc.imread('my_own_images/2828_my_own_image.png', flatten=True)\n",
    "    \n",
    "# reshape from 28x28 to list of 784 values, invert values\n",
    "img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "# then scale data to range from 0.01 to 1.0\n",
    "img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "print(\"min = \", numpy.min(img_data))\n",
    "print(\"max = \", numpy.max(img_data))\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(img_data)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
